{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvigâ€™s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checklist (TODO: delete before submission):\n",
        "- [x] Implement unigram model\n",
        "- [x] Implement bigram model\n",
        "- [ ] Implement trigram model\n",
        "- [ ] Implement quigram model\n",
        "- [x] Implement Levenstein error model\n",
        "- [ ] Implement QWERTY-aware error model\n",
        "- [ ] Construct a test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MoQeEsZvHvvi"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from collections import defaultdict\n",
        "\n",
        "import tqdm.notebook as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LanguageModel(ABC):\n",
        "    \"\"\"Abstract context-aware language model.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, candidates: list[str], pretext: list[str],\n",
        "                 posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Predict the probability of the word given the context.\n",
        "        \n",
        "        Args:\n",
        "            candidates (list[str]): Set of candidate replacements.\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            posttext (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from candidate set to the probability of\n",
        "                the candidate in the context.\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ErrorModel(ABC):\n",
        "    \"\"\"Abstract model for typo probabilities.\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def __call__(self, word: str, candidate: str) -> float:\n",
        "        \"\"\"Returns the probability of word being a misspelled candidate word.\n",
        "        \n",
        "        Args:\n",
        "            word (str): Word that is typed.\n",
        "            candidate (str): Misspeling correction candidate.\n",
        "\n",
        "        Returns:\n",
        "            float: Probability of word being a misspelled candidate word.\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Corrector:\n",
        "    \"\"\"Context-aware text corrector.\n",
        "\n",
        "    Attributes:\n",
        "        candidates (set[str]): Set of candidate words to choose from.\n",
        "        language_model (LanguageModel): Context-aware language model to\n",
        "            predict probabilities of words occuring in a given context.\n",
        "        error_model (ErrorModel): Model for predicting the probability\n",
        "            of mispelling one word as another.\n",
        "        context_size (int): Size of the context given to the language\n",
        "            model. Does not include the word itselt. Counted individually\n",
        "            for each direction (in the text \"a b c d e\", context of \"c\" is\n",
        "            (\"b\", \"d\"), given `context_size` = 1.) Defaults to 10.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        candidates: set[str],\n",
        "        language_model: LanguageModel,\n",
        "        error_model: ErrorModel,\n",
        "        context_size: int = 10,\n",
        "    ):\n",
        "        \"\"\"Context-aware text corrector.\n",
        "\n",
        "        Args:\n",
        "            candidates (set[str]): Set of candidate words to choose from.\n",
        "            language_model (LanguageModel): Context-aware language model to\n",
        "                predict probabilities of words occuring in a given context.\n",
        "            error_model (ErrorModel): Model for predicting the probability\n",
        "                of mispelling one word as another.\n",
        "            context_size (int): Size of the context given to the language\n",
        "                model. Does not include the word itselt. Counted individually\n",
        "                for each direction (in the text \"a b c d e\", context of \"c\" is\n",
        "                (\"b\", \"d\"), given `context_size` = 1.) Defaults to 10.\n",
        "        \"\"\"\n",
        "        self.candidates = candidates\n",
        "        self.language_model = language_model\n",
        "        self.error_model = error_model\n",
        "        self.context_size = context_size\n",
        "\n",
        "    def __call__(self,\n",
        "                 text: list[str],\n",
        "                 verbose: bool = False) -> list[tuple[str, float, float]]:\n",
        "        \"\"\"Returns the most likely candidate, probability of the candidate,\n",
        "        and the probability of the original word occuring in a 2 *`context_size`\n",
        "        context window.\n",
        "\n",
        "        Args:\n",
        "            text (list[str]): Text to correct. \n",
        "            verbose (bool): Whether to display the progress bar or not. Defaults\n",
        "                to `False`.\n",
        "        \n",
        "        Returns:\n",
        "            list[tuple[str, float, float]]: The candidate word, probability of\n",
        "                candidate, and probability of the original word corresponding\n",
        "                to each word in the original text.\n",
        "        \"\"\"\n",
        "        result = [None] * len(text)\n",
        "        for i, word in tqdm.tqdm(enumerate(text),\n",
        "                                 total=len(text),\n",
        "                                 disable=not verbose):\n",
        "            pretext = text[max(0, i - self.context_size):i]\n",
        "            posttext = text[i + 1:i + self.context_size + 1]\n",
        "            candidates = self.candidates.copy() - {word}\n",
        "            candidate_probs = self.language_model(candidates, pretext,\n",
        "                                                  posttext)\n",
        "            word_prob = self.language_model({word}, pretext, posttext)[word]\n",
        "\n",
        "            def get_prob(candidate):\n",
        "                return self.error_model(word,\n",
        "                                        candidate) * candidate_probs[candidate]\n",
        "\n",
        "            correction = max(candidates, key=get_prob)\n",
        "            probability = get_prob(correction)\n",
        "            result[i] = (correction, probability, word_prob)\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NGramLanguageModel(LanguageModel):\n",
        "    \"\"\"N-gram language model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, text: list[str], n: int = 3, verbose: bool = False):\n",
        "        text = text.copy()\n",
        "        self.total = len(text)\n",
        "        self.prefix = defaultdict(lambda: 0)\n",
        "        pbar = tqdm.tqdm(total=(2 * n * (len(text) + 1) - n * (n + 1) // 2))\n",
        "        for k in range(1, n + 1):\n",
        "            for i in range(len(text) - k + 1):\n",
        "                self.prefix[text[i:i + k]] += 1\n",
        "                pbar.update()\n",
        "        self.prefix[tuple()] = self.total\n",
        "        text.reverse()\n",
        "        self.postfix = defaultdict(lambda: 0)\n",
        "        for k in range(1, n + 1):\n",
        "            for i in range(len(text) - k):\n",
        "                self.postfix[text[i:i + k]] += 1\n",
        "                pbar.update()\n",
        "        self.postfix[tuple()] = self.total\n",
        "        self.n = n\n",
        "        pbar.close()\n",
        "\n",
        "    def __call__(self, candidates: list[str], pretext: list[str],\n",
        "                 posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Predict the probability of the word using bigram data.\n",
        "\n",
        "        Args:\n",
        "            candidates (list[str]): Set of candidate replacements.\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            posttext (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from candidate set to the probability of\n",
        "                the candidate in the context.\n",
        "        \"\"\"\n",
        "        pretext = tuple(pretext[max(0, len(pretext) - self.n):])\n",
        "        posttext = tuple(posttext[:self.n][::-1])\n",
        "        result = {}\n",
        "        for candidate in candidates:\n",
        "            prev_prob = (self.prefix[pretext + (candidate, )] + 1) / (self.prefix[pretext] + 2)\n",
        "            next_prob = (self.postfix[posttext + (candidate, )] + 1) / (self.postfix[posttext] + 2)\n",
        "            result[candidate] = prev_prob * next_prob\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FrequenciesLanguageModel(LanguageModel):\n",
        "    \"\"\"Language model that predicts the probability of the word based on its\n",
        "    frequency. Does not take the context into account.\n",
        "\n",
        "    Attributes:\n",
        "        total (int): Total number of words in the training set.\n",
        "        probabilities (dict[str, float]): Mapping from the word to its\n",
        "            probability in the training set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, frequencies: dict[str, int]):\n",
        "        \"\"\"Language model that predicts the probability of the word based on its\n",
        "        frequency. Does not take the context into account.\n",
        "\n",
        "        Args:\n",
        "            frequencies (dict[str, int]): Mapping from the word to its frequency\n",
        "                in the training set.\n",
        "        \"\"\"\n",
        "        self.total = sum(frequencies.values())\n",
        "        self.probabilities = {\n",
        "            word: count / self.total\n",
        "            for word, count in frequencies.items()\n",
        "        }\n",
        "\n",
        "    def __call__(self, candidates: list[str], pretext: list[str],\n",
        "                 posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Predict the probability of the word.\n",
        "        \n",
        "        Args:\n",
        "            candidates (list[str]): Set of candidate replacements.\n",
        "            pretext (list[str]): Context preceeding the word. Ignored.\n",
        "            posttext (list[str]): Context after the word. Ignored.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from candidate set to the probability of\n",
        "                the candidate in the context.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            word: self.probabilities.get(word, 1 / (self.total + 2))\n",
        "            for word in candidates\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BigramsLanguageModel(LanguageModel):\n",
        "    \"\"\"Bigram language model.\n",
        "\n",
        "    Attributes:\n",
        "        totals (dict[str, int]): Count of bigrams starting with each word in the\n",
        "            training set.\n",
        "        probabilities (dict[str, float]): Mapping from bigrams to their\n",
        "            probabilities in the training set.\n",
        "        total (int): Total number of bigrams in the training set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bigrams: dict[tuple[str, str], int]):\n",
        "        \"\"\"Bigram language model.\n",
        "        \n",
        "        Args:\n",
        "            bigrams (dict[tuple[str, str], int]): Mapping from bigrams to their\n",
        "                counts in the training set.\n",
        "        \"\"\"\n",
        "        self.totals = defaultdict(lambda: 0)\n",
        "        for (word, _), count in bigrams.items():\n",
        "            self.totals[word] += count\n",
        "        self.probabilities = {\n",
        "            (a, b): count / self.totals[a]\n",
        "            for (a, b), count in bigrams.items()\n",
        "        }\n",
        "        self.total = sum(self.totals.values())\n",
        "\n",
        "    def __call__(self, candidates: list[str], pretext: list[str],\n",
        "                 posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Predict the probability of the word using bigram data.\n",
        "\n",
        "        Args:\n",
        "            candidates (list[str]): Set of candidate replacements.\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            posttext (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from candidate set to the probability of\n",
        "                the candidate in the context.\n",
        "        \"\"\"\n",
        "        prev = pretext[-1] if pretext else None\n",
        "        next = posttext[0] if posttext else None\n",
        "        result = {}\n",
        "        for candidate in candidates:\n",
        "            if prev is None:\n",
        "                prev_prob = 1\n",
        "            elif (prev, candidate) not in self.probabilities:\n",
        "                prev_prob = 1 / (self.totals[prev] + 2)\n",
        "            else:\n",
        "                prev_prob = self.probabilities[(prev, candidate)]\n",
        "            if next is None:\n",
        "                next_prob = 1\n",
        "            elif (candidate, next) not in self.probabilities:\n",
        "                next_prob = 1 / (self.totals[next] + 2)\n",
        "            else:\n",
        "                next_prob = self.probabilities[(candidate, next)]\n",
        "            result[candidate] = prev_prob * next_prob\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LevensteinErrorModel(ErrorModel):\n",
        "    \"\"\"Error model based on Levenstein distance.\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, word: str, candidate: str, base: float = 2) -> float:\n",
        "        \"\"\"Calculate the probability of the word being a mispelling of the\n",
        "        candidate.\n",
        "\n",
        "        Args:\n",
        "            word (str): Word that is typed.\n",
        "            candidate (str): Candidate word.\n",
        "        \n",
        "        Returns:\n",
        "            float: Probability of word being a mispelling of candidate.\n",
        "        \"\"\"\n",
        "        dp = [[0] * (len(candidate) + 1) for _ in range(len(word) + 1)]\n",
        "        for i in range(len(candidate)):\n",
        "            dp[0][i + 1] = i + 1\n",
        "        for i in range(len(word)):\n",
        "            dp[i + 1][0] = i + 1\n",
        "        for i in range(1, len(word) + 1):\n",
        "            for j in range(1, len(candidate) + 1):\n",
        "                dp[i][j] = min(dp[i - 1][j], dp[i][j - 1]) + 1\n",
        "                if word[i - 1] == candidate[j - 1]:\n",
        "                    dp[i][j] = dp[i - 1][j - 1]\n",
        "        return pow(base, -dp[-1][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb32d0349fbd4810a3efcba4cdb31097",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with open('bigrams.txt', encoding='iso-8859-1') as file:\n",
        "    unigrams = defaultdict(lambda: 0) \n",
        "    bigrams = defaultdict(lambda: 0) \n",
        "    for line in tqdm.tqdm(file):\n",
        "        count, a, b = line.split()\n",
        "        count = int(count)\n",
        "        unigrams[a] += count\n",
        "        bigrams[(a, b)] += count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "unigram_lm = FrequenciesLanguageModel(unigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigram_lm = BigramsLanguageModel(bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "levenstein_error = LevensteinErrorModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "candidates = set(sorted(unigrams.keys(), key=unigrams.__getitem__, reverse=True)[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "corrector = Corrector(candidates, bigram_lm, levenstein_error, context_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "*Your text here...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
