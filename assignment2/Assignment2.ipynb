{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvigâ€™s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MoQeEsZvHvvi"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from collections import defaultdict, Counter\n",
        "import itertools\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tqdm.notebook as tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Language models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LanguageModel(ABC):\n",
        "    \"\"\"Abstract context-aware language model.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, candidates: list[str], pretext: list[str],\n",
        "                 posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Predict the probability of the word given the context.\n",
        "        \n",
        "        Args:\n",
        "            candidates (list[str]): Set of candidate replacements.\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            posttext (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from candidate set to the probability of\n",
        "                the candidate in the context.\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NGramLanguageModel(LanguageModel):\n",
        "    \"\"\"N-gram language model.\n",
        "\n",
        "    Attributes:\n",
        "        total (int): Total number of words in the training set.\n",
        "        prefix (dict[str, int]): Mapping from a n-gram to a count of the n-gram\n",
        "            in the training set.\n",
        "        suffix (dict[str, int]): Mapping from a reversed n-gram to a count of\n",
        "            the n-gram in the training set. E.g. if suffix[('a', 'b')] = 3,\n",
        "            then ('b', 'a') occurs 3 times in training dataset.\n",
        "        n (int): Number of words in n-grams.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, counts: dict[tuple[str], int], n: int = 3):\n",
        "        \"\"\"Initializes a n-gram language model.\n",
        "\n",
        "        Args:\n",
        "            counts (dict[tuple[str], int]): Mapping from n-gram to the number of\n",
        "                times it occurs in the training set.\n",
        "            n (int): Number of words in n-grams. Defaults to 3.\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.total = sum(counts.values())\n",
        "        self.prefix = defaultdict(lambda: 0)\n",
        "        self.suffix = defaultdict(lambda: 0)\n",
        "        # Fill n-grams dictionaries with all k-grams with k <= n\n",
        "        for gram, count in counts.items():\n",
        "            for k in range(1, n + 1):\n",
        "                if len(gram) < k:\n",
        "                    continue\n",
        "                kgram = gram[:k]\n",
        "                self.prefix[kgram] += count\n",
        "                kgram = kgram[::-1]\n",
        "                self.suffix[kgram] += count\n",
        "        self.suffix[tuple()] = self.prefix[tuple()] = self.total\n",
        "\n",
        "\n",
        "    def __call__(self, candidates: list[str], pretext: list[str],\n",
        "                 posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Predict the probability of the word using n-gram data.\n",
        "\n",
        "        Args:\n",
        "            candidates (list[str]): Set of candidate replacements.\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            posttext (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from candidate set to the probability of\n",
        "                the candidate in the context.\n",
        "        \"\"\"\n",
        "        pretext = tuple(pretext[-self.n+1:])\n",
        "        # Posttext is reversed to find the conditional probability\n",
        "        posttext = tuple(posttext[:self.n - 1][::-1])\n",
        "        result = {}\n",
        "        for candidate in candidates:\n",
        "            # Use beta distribution mean to smooth the probabilities for\n",
        "            # infrequent words\n",
        "            prev_prob = (self.prefix[pretext + (candidate, )] +\n",
        "                         1) / (self.prefix[pretext] + 2)\n",
        "            next_prob = (self.suffix[posttext + (candidate, )] +\n",
        "                         1) / (self.suffix[posttext] + 2)\n",
        "            result[candidate] = prev_prob * next_prob\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ErrorModel(ABC):\n",
        "    \"\"\"Abstract model for typo probabilities.\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def __call__(self, word: str, candidate: str) -> float:\n",
        "        \"\"\"Returns the probability of word being a misspelled candidate word.\n",
        "        \n",
        "        Args:\n",
        "            word (str): Word that is typed.\n",
        "            candidate (str): Misspeling correction candidate.\n",
        "\n",
        "        Returns:\n",
        "            float: Probability of word being a misspelled candidate word.\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LevensteinErrorModel(ErrorModel):\n",
        "    \"\"\"Error model based on Levenstein distance.\n",
        "\n",
        "    Attributes:\n",
        "        base (float): Probability of word being a misspelling of candidate word\n",
        "            is calculated as base^d, where d is the Levenstein distance between\n",
        "            the word and the candidate.\n",
        "    \"\"\"\n",
        "    def __init__(self, base: float = 4):\n",
        "        \"\"\"Initializes the error model.\n",
        "        \n",
        "        Args:\n",
        "            base (float): Probability of word being a misspelling of candidate word\n",
        "                is calculated as base^d, where d is the Levenstein distance between\n",
        "                the word and the candidate.\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "\n",
        "    def __call__(self, word: str, candidate: str) -> float:\n",
        "        \"\"\"Calculate the probability of the word being a misspelling of the\n",
        "        candidate.\n",
        "\n",
        "        Args:\n",
        "            word (str): Word that is typed.\n",
        "            candidate (str): Candidate word.\n",
        "        \n",
        "        Returns:\n",
        "            float: Probability of word being a misspelling of candidate.\n",
        "        \"\"\"\n",
        "        word = word.lower()\n",
        "        candidate = candidate.lower()\n",
        "        dp = [[0] * (len(candidate) + 1) for _ in range(len(word) + 1)]\n",
        "        for i in range(len(candidate)):\n",
        "            dp[0][i + 1] = i + 1\n",
        "        for i in range(len(word)):\n",
        "            dp[i + 1][0] = i + 1\n",
        "        for i in range(1, len(word) + 1):\n",
        "            for j in range(1, len(candidate) + 1):\n",
        "                dp[i][j] = min(dp[i - 1][j], dp[i][j - 1]) + 1\n",
        "                if word[i - 1] == candidate[j - 1]:\n",
        "                    dp[i][j] = dp[i - 1][j - 1]\n",
        "        return pow(self.base, -dp[-1][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Corrector class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Corrector:\n",
        "    \"\"\"Context-aware text corrector.\n",
        "\n",
        "    Attributes:\n",
        "        candidates (set[str]): Set of candidate words to choose from.\n",
        "        language_model (LanguageModel): Context-aware language model to\n",
        "            predict probabilities of words occuring in a given context.\n",
        "        error_model (ErrorModel): Model for predicting the probability\n",
        "            of misspelling one word as another.\n",
        "        context_size (int): Size of the context given to the language\n",
        "            model. Does not include the word itselt. Counted individually\n",
        "            for each direction (in the text \"a b c d e\", context of \"c\" is\n",
        "            (\"b\", \"d\"), given `context_size` = 1.) Defaults to 10.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        candidates: set[str],\n",
        "        language_model: LanguageModel,\n",
        "        error_model: ErrorModel,\n",
        "        context_size: int = 10,\n",
        "    ):\n",
        "        \"\"\"Context-aware text corrector.\n",
        "\n",
        "        Args:\n",
        "            candidates (set[str]): Set of candidate words to choose from.\n",
        "            language_model (LanguageModel): Context-aware language model to\n",
        "                predict probabilities of words occuring in a given context.\n",
        "            error_model (ErrorModel): Model for predicting the probability\n",
        "                of misspelling one word as another.\n",
        "            context_size (int): Size of the context given to the language\n",
        "                model. Does not include the word itselt. Counted individually\n",
        "                for each direction (in the text \"a b c d e\", context of \"c\" is\n",
        "                (\"b\", \"d\"), given `context_size` = 1.) Defaults to 10.\n",
        "        \"\"\"\n",
        "        self.candidates = candidates\n",
        "        self.language_model = language_model\n",
        "        self.error_model = error_model\n",
        "        self.context_size = context_size\n",
        "\n",
        "    @staticmethod\n",
        "    def get_words(text: str) -> list[str]:\n",
        "        \"\"\"Returns words in the string.\n",
        "        \n",
        "        Args:\n",
        "            text (str): Text to extract the word from.\n",
        "        \n",
        "        Returns:\n",
        "            list[str]: Words in the given text.\n",
        "        \"\"\"\n",
        "        return re.findall('\\\\w+', text)\n",
        "\n",
        "    @staticmethod\n",
        "    def replace_words(text: str, words: list[str]) -> str:\n",
        "        \"\"\"Replaces words in the text by the list of given words.\n",
        "\n",
        "        Args:\n",
        "            text (str): Text to replace the words in.\n",
        "            words (list[str]): List of replacements words.\n",
        "        \n",
        "        Returns:\n",
        "            str: Text with words replaced.\n",
        "        \"\"\"\n",
        "\n",
        "        def copy_capitalization(src: str, dst: str) -> str:\n",
        "            if src[0].isupper():\n",
        "                return dst.capitalize()\n",
        "            else:\n",
        "                return dst\n",
        "\n",
        "        filler = re.split('\\\\w+', text)\n",
        "        original_words = Corrector.get_words(text)\n",
        "        assert len(original_words) == len(words)\n",
        "        words = list(\n",
        "            map(lambda x: copy_capitalization(*x), zip(original_words, words)))\n",
        "        assert len(filler) == len(words) + 1\n",
        "        return ''.join(itertools.chain(*zip(filler, words + [''])))\n",
        "\n",
        "    def correct_words(self, words: list[str]) -> list[str]:\n",
        "        \"\"\"Corrects the words, and returns the list of words after correction.\n",
        "        Expects all words to be in lowercase.\n",
        "\n",
        "        Args:\n",
        "            words (list[str]): Words to correct.\n",
        "        \n",
        "        Returns:\n",
        "            list[str]: Corrected words.\n",
        "        \"\"\"\n",
        "        result = words.copy()\n",
        "        for i, word in enumerate(words):\n",
        "            pretext = words[i - self.context_size:i]\n",
        "            posttext = words[i + 1:i + self.context_size + 1]\n",
        "            candidates = self.candidates - {word}\n",
        "            candidate_probs = self.language_model(candidates, pretext,\n",
        "                                                  posttext)\n",
        "            word_prob = self.language_model({word}, pretext, posttext)[word]\n",
        "\n",
        "            def get_prob(candidate: str) -> float:\n",
        "                return candidate_probs[candidate] * self.error_model(\n",
        "                    word, candidate)\n",
        "            \n",
        "            correction = max(candidates, key=get_prob)\n",
        "            if get_prob(correction) >  1e4 * word_prob:\n",
        "                result[i] = correction\n",
        "        return result\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        lines: list[str],\n",
        "    ) -> list[str]:\n",
        "        \"\"\"Corrects lines and returns the corrected version.\n",
        "\n",
        "        Args:\n",
        "            lines (list[str]): Text lines to correct.    \n",
        "        \n",
        "        Returns:\n",
        "            list[str]: Corrected lines.\n",
        "        \"\"\"\n",
        "        result = []\n",
        "        for line in lines:\n",
        "            words = self.get_words(line.lower())\n",
        "            corrected_words = self.correct_words(words)\n",
        "            corrected_line = self.replace_words(line, corrected_words)\n",
        "            result.append(corrected_line)\n",
        "        return result\n",
        "\n",
        "    def get_candidates(self, pretext: list[str], word: str,\n",
        "                       posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Returns probabilities associated with each candidate for a given\n",
        "        context. Used for testing.\n",
        "\n",
        "        Args:\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            word (str): Typed word.\n",
        "            postfix (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from each candidate to the probability\n",
        "                of it being the word that was meant to be typed.\n",
        "        \"\"\"\n",
        "        candidates = self.candidates.copy() - {word}\n",
        "        candidate_probs = self.language_model(candidates, pretext, posttext)\n",
        "\n",
        "        def get_prob(candidate):\n",
        "            return self.error_model(word, candidate) *\\\n",
        "                   candidate_probs[candidate]\n",
        "\n",
        "        return {candidate: get_prob(candidate) for candidate in candidates}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "fivegrams = dict()\n",
        "with open('fivegrams.txt') as file:\n",
        "    for line in file:\n",
        "        count, *gram = line.split()\n",
        "        gram = tuple(gram)\n",
        "        count = int(count)\n",
        "        fivegrams[gram] = count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigrams = dict()\n",
        "with open('bigrams.txt', encoding='iso-8859-1') as file:\n",
        "    for line in file:\n",
        "        count, *gram = line.split()\n",
        "        gram = tuple(gram)\n",
        "        count = int(count)\n",
        "        bigrams[gram] = count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('wikipedia.txt') as file:\n",
        "    spelling_mistakes = {}\n",
        "    for line in file:\n",
        "        line = line.replace(':', '')\n",
        "        word, *misspellings = line.split()\n",
        "        spelling_mistakes[word] = misspellings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \"The hound of the Baskervilles\" by Arthur Conan Doyle\n",
        "with open('pg3070.txt') as file:\n",
        "    val_text = file.read().lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset = list[tuple[tuple[list[str], str, list[str]], str]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_test_dataset(\n",
        "    text: str,\n",
        "    spelling_mistakes: dict[str, list[str]],\n",
        "    context_size: int = 10\n",
        ") -> Dataset:\n",
        "    \"\"\"Generates a test/validation dataset from a text. First, extracts words\n",
        "    using a simple regular expression, then, for each word, generates a test\n",
        "    case by replacing the word by corresponding misspelled versions from\n",
        "    `spelling_mistakes`.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to generate the dataset from.\n",
        "        spelling_mistakes (dict[str, list[str]]): Mapping from a word to possible\n",
        "            misspellings.\n",
        "        context_size: Context to include in the test case. Omnidirectional, does\n",
        "            not include the word itself. Size of context is counted individually\n",
        "            in each direction.\n",
        "\n",
        "    Returns:\n",
        "        list[input, target]: Input is a tuple of pretext, word, and posttext, and\n",
        "            target is the original word being replaced.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    words = re.findall('\\\\w+', text)\n",
        "    result = []\n",
        "    for i, word in enumerate(words):\n",
        "        if word not in spelling_mistakes:\n",
        "            continue\n",
        "        pretext = words[i - context_size:i]\n",
        "        posttext = words[i + 1:i + context_size + 1]\n",
        "        for misspelling in spelling_mistakes[word]:\n",
        "            result.append(((pretext, misspelling, posttext), word))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_accuracy(\n",
        "    dataset: Dataset,\n",
        "    corrector: Corrector,\n",
        "    verbose: bool = False,\n",
        ") -> float:\n",
        "    \"\"\"Calculates the accuracy of the corrector on the dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: Testing dataset.\n",
        "        corrector (Corrector): Corrector to test.\n",
        "        verbose: Whether to display the progress bar or not. Defaults to `False`.\n",
        "    \n",
        "    Returns:\n",
        "        float: Accuracy on the dataset. Between 0 and 1 inclusive.\n",
        "    \"\"\"\n",
        "    total = len(dataset)\n",
        "    accurate = 0\n",
        "    for (pretext, word, posttext), target in tqdm.tqdm(dataset,\n",
        "                                                       disable=not verbose):\n",
        "        probs = corrector.get_candidates(pretext, word, posttext)\n",
        "        prediction = max(probs, key=probs.__getitem__)\n",
        "        if prediction == target:\n",
        "            accurate += 1\n",
        "    return accurate / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_corrector(\n",
        "    n: int,\n",
        "    training_set: dict[tuple[str], int],\n",
        "    levenstein_base: float,\n",
        "    candidates_size: int,\n",
        "    val_set: Dataset,\n",
        ") -> tuple[float, Corrector]:\n",
        "    \"\"\"Creates, trains, and evaluates a corrector according to the given parameters.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of words in n-grams.\n",
        "        training_set (dict[tuple[str], int]): Counts of n-grams in the training\n",
        "            set.\n",
        "        candidates_size (int): Size of the candidates set.\n",
        "        val_set (Dataset): Set to evaluate corrector on.\n",
        "\n",
        "    Returns:\n",
        "        tuple[float, Corrector]: Accuracy of the model and the trained model.\n",
        "    \"\"\"\n",
        "    lm = NGramLanguageModel(training_set, n=n)\n",
        "    em = LevensteinErrorModel(base=levenstein_base)\n",
        "\n",
        "    def get_count(word):\n",
        "        return lm.prefix[\n",
        "            (word),\n",
        "        ]\n",
        "\n",
        "    candidates = sorted({gram[0]\n",
        "                         for gram in training_set.keys()},\n",
        "                        key=get_count,\n",
        "                        reverse=True)\n",
        "    candidates = candidates[:candidates_size]\n",
        "    candidates = set(candidates)\n",
        "    corrector = Corrector(candidates, lm, em)\n",
        "    return get_accuracy(val_set, corrector), corrector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_matrix(matrix: dict[str, list]) -> tuple[dict, float, Corrector]:\n",
        "    \"\"\"Tests all combinations of hyperparameters in the matrix, and returns\n",
        "    best parameters, score, and model.\n",
        "\n",
        "    Args:\n",
        "        matrix (dict[str, list]): Matrix with hyperparameters that should be\n",
        "            passed into `test_corrector`.\n",
        "    \n",
        "    Returns:\n",
        "        tuple[dict, float, Corrector]: Best hyperparameters, accuracy, and\n",
        "            model respectively.\n",
        "    \"\"\"\n",
        "    keys = sorted(matrix.keys())\n",
        "    iterables = [matrix[key] for key in keys]\n",
        "    best_values = None\n",
        "    best_score = -float('inf')\n",
        "    best_model = None\n",
        "    cases = list(itertools.product(*iterables))\n",
        "    for values in tqdm.tqdm(cases):\n",
        "        kwargs = dict(zip(keys, values))\n",
        "        accuracy, model = test_corrector(**kwargs)\n",
        "        if accuracy > best_score:\n",
        "            best_values = dict(zip(keys, values))\n",
        "            best_score = accuracy\n",
        "            best_model = model\n",
        "    return best_values, best_score, best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "test_dataset = generate_test_dataset(val_text, spelling_mistakes)\n",
        "cases_by_target = defaultdict(list)\n",
        "for case, target in test_dataset:\n",
        "    cases_by_target[target].append(case)\n",
        "test_dataset = []\n",
        "for _ in range(10):\n",
        "    for target, cases in cases_by_target.items():\n",
        "        test_dataset.append((random.choice(cases), target))\n",
        "random.shuffle(test_dataset)\n",
        "val_dataset, test_dataset = test_dataset[:100], test_dataset[100:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "matrix = {\n",
        "    'n': [2],\n",
        "    'training_set': [bigrams],\n",
        "    'levenstein_base': [2, 8, 32, 128, 512, 2048],\n",
        "    'candidates_size': [100000],\n",
        "    'val_set': [val_dataset],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72d9332a823e43e1974d1fc7354b0cb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "_values, score, model = test_matrix(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the validation set: 75.0%\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy on the validation set: {score * 100:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most of the hyperparameters, as well as training dataset are chosen experimentally (see \"Finding the best hyperparameters\" for details,) so they won't be mentioned here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "### Language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The language model is a $n$-gram model, using beta distribution mean value to smooth the probabilities:\n",
        "$$\n",
        "\\begin{array}{rl}\n",
        "\\hat{P}(w_n|w_1..w_{n-1}) &= \\mu\\left[\\Beta(\\#(w_1..w_n) + 1, \\#(w_1..w_{n-1}) - \\#(w_1..w_n) + 1)\\right] = \\\\\n",
        "                    &= \\frac{\\#(w_1..w_n) + 1}{\\#(w_1..w_{n-1}) + 2}\n",
        "\\end{array}\n",
        "$$\n",
        "Where $\\#(w_1..w_n)$ is the number of times n-gram $w_1..w_n$ occurs in the training set.\n",
        "Given a preceeding context $U = u_1..u_{n-1}$, and succeeding context $V = v_1..v_{n-1}$, the probability of word $w$ occurring is:\n",
        "$$\\hat{P}(w|U,V) = \\hat{P}(w|U)\\hat{P}(w|V)$$\n",
        "Beta distribution is a natural choice when dealing with probabilities, as it is a conjugate prior distribution for Bernoulli distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Error model is meant to predict the probability of word $w$ being a misspelling of the candidate word $c$ $\\mathcal{P}(c|w)$. To define this probability, let us introduce the notion of Levenstein distance first:\n",
        "$$d(u, v) = f(|u|, |v|)$$\n",
        "$$f(i, j) = \\begin{cases}\n",
        "0, &i = 0 \\land j = 0 \\\\\n",
        "i, &j = 0 \\\\\n",
        "j, &i = 0 \\\\\n",
        "f(i - 1, j - 1), &u_i = v_j \\\\\n",
        "\\min \\left\\{ f(i - 1, j), f(i, j - 1) \\right\\}, &\\text{otherwise} \\\\\n",
        "\\end{cases}$$\n",
        "Probability $\\mathcal{P}(c|w)$ is then:\n",
        "$$\\mathcal{P}(c|w) = b^{-d(c, w)}$$\n",
        "Where $b$ is a hyperparameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Corrector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given the context pair $(U, V)$ and the word $w$, the probability of word $w$ being a mispelling of candidate word $c \\in C$ is simply:\n",
        "$$P(c|w,U,V) = \\hat{P}(c|U,V) \\mathcal{P}(c|w)$$\n",
        "Most likely candidate $c'$ is selected purely on this probability:\n",
        "$$c' = \\mathop{\\text{argmax}}\\limits_{c \\in C} P(c|w,U,V)$$\n",
        "\n",
        "The word is then replaced with the corrected version if:\n",
        "$$\\lambda\\hat{P}(w|U,V) < P(c|w,U,V)$$\n",
        "Where $\\lambda$ is a threshold constant, chosen empirically to be $10^4$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Note: the test dataset and evaluation functions are defined in the \"Finding the best hyperparameters\" section\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75f0181c8c2441c984f65510439d2043",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_accuracy = get_accuracy(test_dataset, model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the test set: 85.0%\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy on the test set: {test_accuracy * 100:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Norvig's solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Spelling Corrector in Python 3; see http://norvig.com/spell-correct.html\n",
        "\n",
        "Copyright (c) 2007-2016 Peter Norvig\n",
        "MIT license: www.opensource.org/licenses/mit-license.php\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Norvig:\n",
        "\n",
        "    @staticmethod\n",
        "    def get_words(text):\n",
        "        return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "    def __init__(self, corpus_file: str) -> None:\n",
        "        with open(corpus_file) as file:\n",
        "            words = self.get_words(file.read())\n",
        "            self.n = len(words)\n",
        "            self.words = Counter(words)\n",
        "\n",
        "    def probability(self, word):\n",
        "        return self.words[word] / self.n\n",
        "\n",
        "    def correction(self, word):\n",
        "        return max(self.candidates(word), key=self.probability)\n",
        "\n",
        "    def candidates(self, word):\n",
        "        return (self.known([word]) or self.known(self.edits1(word))\n",
        "                or self.known(self.edits2(word)) or [word])\n",
        "\n",
        "    def known(self, words):\n",
        "        return set(words) & set(self.words)\n",
        "\n",
        "    @staticmethod\n",
        "    def edits1(word):\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "    @staticmethod\n",
        "    def edits2(word):\n",
        "        return {e2 for e1 in Norvig.edits1(word) for e2 in Norvig.edits1(e1)}\n",
        "\n",
        "    def get_candidates(self, pretext: list[str], word: str,\n",
        "                       posttext: list[str]) -> dict[str, float]:\n",
        "        \"\"\"Returns probabilities associated with each candidate for a given\n",
        "        context. Used for testing.\n",
        "\n",
        "        Args:\n",
        "            pretext (list[str]): Context preceeding the word.\n",
        "            word (str): Typed word.\n",
        "            postfix (list[str]): Context after the word.\n",
        "        \n",
        "        Returns:\n",
        "            dict[str, float]: Mapping from each candidate to the probability\n",
        "                of it being the word that was meant to be typed.\n",
        "        \"\"\"\n",
        "        candidates = set(self.candidates(word)) - {word}\n",
        "        correction = self.correction(word)\n",
        "        result = dict.fromkeys(candidates, 0)\n",
        "        result[correction] = 1\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "norvig = Norvig('big.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06ed1f829162465a9bdfe0644de591ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "norvig_accuracy = get_accuracy(test_dataset, norvig, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the test set: 84.0%\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy on the test set: {norvig_accuracy * 100:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Final accuracies on the test set are:\n",
        "\n",
        "| Norvig | N-gram |\n",
        "| --- | --- |\n",
        "| 84.0% | 85.0% |\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
